# AI å¼•æ“è®¾è®¡

å¤©æœºçˆ»çš„æ ¸å¿ƒç«äº‰åŠ›åœ¨äºå…¶æ™ºèƒ½åŒ–çš„ AI è§£è¯»ç³»ç»Ÿï¼Œæ·±åº¦é›†æˆ **OpenAI GPT-4** æ¨¡å‹ï¼Œç»“åˆä¼ ç»Ÿå‘½ç†çŸ¥è¯†å›¾è°±ï¼Œæä¾›ä¸“ä¸šã€æ¸©æš–ã€ä¸ªæ€§åŒ–çš„å‘½ç†åˆ†æã€‚

## AI æ¶æ„æ€»è§ˆ

```
ç”¨æˆ·è¾“å…¥ï¼ˆç”Ÿè¾°å…«å­—ï¼‰
    â†“
å‘½ç†ç®—æ³•è®¡ç®—ï¼ˆæ’ç›˜ï¼‰
    â†“
ç»“æ„åŒ–æ•°æ®æå–
    â†“
çŸ¥è¯†å›¾è°±æŸ¥è¯¢
    â†“
Prompt å·¥ç¨‹ï¼ˆä¸Šä¸‹æ–‡æ„å»ºï¼‰
    â†“
OpenAI GPT-4 æ¨¡å‹
    â†“
ç»“æœåå¤„ç†ä¸ä¼˜åŒ–
    â†“
å¤šè¯­è¨€è¾“å‡º
```

## æ ¸å¿ƒæŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç”¨é€” |
|------|------|
| OpenAI GPT-4 Turbo | æ ¸å¿ƒè§£è¯»æ¨¡å‹ |
| Azure OpenAI Service | ä¼ä¸šçº§ API æœåŠ¡ |
| Pinecone | å‘é‡æ•°æ®åº“ï¼ˆçŸ¥è¯†æ£€ç´¢ï¼‰|
| LangChain | AI å·¥ä½œæµç¼–æ’ |
| Azure Cognitive Services | è¯­éŸ³åˆæˆã€ç¿»è¯‘ |

## AI è§£è¯»æµç¨‹

### 1. æ•°æ®é¢„å¤„ç†

```typescript
// lib/ai/preprocessor.ts
interface BirthData {
  year: number;
  month: number;
  day: number;
  hour: number;
  gender: 'male' | 'female';
}

export function preprocessBirthData(data: BirthData) {
  // è®¡ç®—å¤©å¹²åœ°æ”¯
  const chart = calculateBaziChart(data);
  
  // æå–äº”è¡Œåˆ†å¸ƒ
  const elements = analyzeElements(chart);
  
  // è¯†åˆ«æ ¼å±€
  const pattern = identifyPattern(chart);
  
  return {
    chart,
    elements,
    pattern,
    metadata: {
      season: getSeason(data.month),
      dayMaster: chart.dayPillar.heavenlyStem,
    }
  };
}
```

### 2. çŸ¥è¯†å›¾è°±æ£€ç´¢

```typescript
// lib/ai/knowledge-retrieval.ts
import { PineconeClient } from '@pinecone-database/pinecone';

export async function retrieveKnowledge(query: string) {
  const pinecone = new PineconeClient();
  await pinecone.init({
    environment: 'us-west1-gcp',
    apiKey: process.env.PINECONE_API_KEY,
  });

  const index = pinecone.Index('bazi-knowledge');
  
  // å‘é‡åŒ–æŸ¥è¯¢
  const embedding = await getEmbedding(query);
  
  // ç›¸ä¼¼åº¦æœç´¢
  const results = await index.query({
    vector: embedding,
    topK: 5,
    includeMetadata: true,
  });
  
  return results.matches.map(m => m.metadata);
}
```

### 3. Prompt å·¥ç¨‹

```typescript
// lib/ai/prompt-builder.ts
export function buildBaziPrompt(data: ProcessedData) {
  const systemPrompt = `
ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­å›½ä¼ ç»Ÿå‘½ç†å­¦çš„ AI å¤§å¸ˆï¼Œä¸“ä¸šäºå…«å­—åˆ†æã€‚
ä½ çš„è§£è¯»åº”è¯¥ï¼š
1. åŸºäºä¼ ç»Ÿå‘½ç†ç†è®ºï¼Œä½†ç”¨ç°ä»£åŒ–çš„è¯­è¨€è¡¨è¾¾
2. å‡†ç¡®ã€ä¸“ä¸šï¼Œä½†æ¸©æš–ã€å¯Œæœ‰åŒç†å¿ƒ
3. é¿å…è¿‡åº¦è´Ÿé¢æˆ–ç»å¯¹åŒ–çš„è¡¨è¿°
4. æä¾›å…·ä½“çš„ã€å¯æ“ä½œçš„å»ºè®®

å½“å‰åˆ†æçš„å‘½ç›˜ä¿¡æ¯ï¼š
- æ—¥ä¸»ï¼š${data.dayMaster}
- äº”è¡Œåˆ†å¸ƒï¼š${JSON.stringify(data.elements)}
- æ ¼å±€ï¼š${data.pattern}
- å­£èŠ‚ï¼š${data.metadata.season}
`;

  const userPrompt = `
è¯·åˆ†æä»¥ä¸‹å…«å­—å‘½ç›˜ï¼Œä»è¿™äº›ç»´åº¦æä¾›è§£è¯»ï¼š

1. **æ€§æ ¼ç‰¹ç‚¹**ï¼ˆ200å­—ï¼‰
   - åŸºäºæ—¥ä¸»å’Œäº”è¡Œåˆ†å¸ƒåˆ†ææ€§æ ¼ä¼˜åŠ¿
   - æŒ‡å‡ºæ½œåœ¨çš„æ€§æ ¼ç›²ç‚¹

2. **äº‹ä¸šå‘å±•**ï¼ˆ200å­—ï¼‰
   - é€‚åˆçš„èŒä¸šæ–¹å‘
   - äº‹ä¸šè¿åŠ¿çš„å‘¨æœŸæ€§å˜åŒ–

3. **æ„Ÿæƒ…å©šå§»**ï¼ˆ200å­—ï¼‰
   - æ„Ÿæƒ…æ¨¡å¼ä¸åå¥½
   - ç†æƒ³ä¼´ä¾£ç±»å‹

4. **å¥åº·å»ºè®®**ï¼ˆ150å­—ï¼‰
   - éœ€è¦æ³¨æ„çš„å¥åº·é—®é¢˜
   - å…»ç”Ÿå»ºè®®

5. **è¡ŒåŠ¨å»ºè®®**ï¼ˆ150å­—ï¼‰
   - 3æ¡å…·ä½“çš„ã€å¯æ‰§è¡Œçš„å»ºè®®

å‘½ç›˜æ•°æ®ï¼š
${JSON.stringify(data.chart, null, 2)}

è¯·ç”¨æ¸©æš–ã€ä¸“ä¸šçš„è¯­æ°”è¿›è¡Œè§£è¯»ã€‚
`;

  return { systemPrompt, userPrompt };
}
```

### 4. OpenAI API è°ƒç”¨

```typescript
// lib/ai/openai-client.ts
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function generateInterpretation(
  systemPrompt: string,
  userPrompt: string,
  options = {}
) {
  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt },
      ],
      temperature: 0.7,
      max_tokens: 2000,
      top_p: 0.9,
      frequency_penalty: 0.3,
      presence_penalty: 0.3,
      ...options,
    });

    return {
      content: completion.choices[0].message.content,
      usage: completion.usage,
      model: completion.model,
    };
  } catch (error) {
    console.error('OpenAI API Error:', error);
    throw new Error('AI è§£è¯»æœåŠ¡æš‚æ—¶ä¸å¯ç”¨');
  }
}
```

### 5. æµå¼è¾“å‡ºï¼ˆå®æ—¶å“åº”ï¼‰

```typescript
// lib/ai/streaming.ts
export async function streamInterpretation(
  systemPrompt: string,
  userPrompt: string
) {
  const stream = await openai.chat.completions.create({
    model: 'gpt-4-turbo-preview',
    messages: [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ],
    stream: true,
    temperature: 0.7,
  });

  return new ReadableStream({
    async start(controller) {
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        controller.enqueue(new TextEncoder().encode(content));
      }
      controller.close();
    },
  });
}
```

## Prompt ä¼˜åŒ–ç­–ç•¥

### Few-shot Learning

```typescript
const fewShotExamples = `
ã€ç¤ºä¾‹ 1ã€‘
å‘½ç›˜ï¼šç”²æœ¨æ—¥ä¸»ï¼Œç”Ÿäºæ˜¥å­£ï¼Œæœ¨æ—º
è§£è¯»ï¼šä½ çš„æ€§æ ¼å¦‚æ˜¥å¤©çš„æ ‘æœ¨ï¼Œå……æ»¡ç”Ÿæœºä¸æ´»åŠ›ã€‚ä½ å¤©ç”Ÿå…·æœ‰å‘ä¸Šç”Ÿé•¿çš„åŠ¨åŠ›...

ã€ç¤ºä¾‹ 2ã€‘
å‘½ç›˜ï¼šåºšé‡‘æ—¥ä¸»ï¼Œç”Ÿäºç§‹å­£ï¼Œé‡‘æ—º
è§£è¯»ï¼šä½ çš„æ€§æ ¼å¦‚ç§‹å¤©çš„é‡‘å±ï¼ŒåšéŸ§è€Œé”‹åˆ©ã€‚ä½ å…·æœ‰å¼ºå¤§çš„æ‰§è¡ŒåŠ›å’Œå†³æ–­åŠ›...
`;
```

### ä¸Šä¸‹æ–‡å‹ç¼©

```typescript
// å‡å°‘ token æ¶ˆè€—
function compressContext(data: ChartData) {
  return {
    dm: data.dayMaster,        // æ—¥ä¸»
    el: data.elements,         // äº”è¡Œ
    pt: data.pattern,          // æ ¼å±€
    // ... åªä¿ç•™å…³é”®ä¿¡æ¯
  };
}
```

### æ¸©åº¦æ§åˆ¶

```typescript
const temperatureMap = {
  personality: 0.8,    // æ€§æ ¼åˆ†æï¼šè¾ƒé«˜åˆ›é€ æ€§
  career: 0.6,         // äº‹ä¸šï¼šå¹³è¡¡
  health: 0.4,         // å¥åº·ï¼šè¾ƒä½åˆ›é€ æ€§ï¼ˆæ›´ä¸¥è°¨ï¼‰
};
```

## AI å®‰å…¨ä¸ä¼¦ç†

### å†…å®¹è¿‡æ»¤

```typescript
// lib/ai/content-filter.ts
const bannedKeywords = [
  'æ­»äº¡', 'ç»ç—‡', 'ç ´äº§', 'ç¦»å©š',
  // ... æ›´å¤šè´Ÿé¢è¯æ±‡
];

export function filterContent(text: string) {
  let filtered = text;
  
  // æ›¿æ¢è´Ÿé¢è¯æ±‡
  bannedKeywords.forEach(keyword => {
    filtered = filtered.replace(
      new RegExp(keyword, 'g'),
      'éœ€è¦æ³¨æ„'
    );
  });
  
  return filtered;
}
```

### å…è´£å£°æ˜

```typescript
const disclaimer = `
ã€é‡è¦æç¤ºã€‘
æœ¬åˆ†æç”± AI åŸºäºä¼ ç»Ÿå‘½ç†ç†è®ºç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒå’Œå¨±ä¹ã€‚
å‘½ç†åˆ†æä¸èƒ½æ›¿ä»£ä¸“ä¸šå’¨è¯¢ï¼ˆå¿ƒç†ã€åŒ»ç–—ã€æ³•å¾‹ç­‰ï¼‰ã€‚
æ‚¨çš„å‘½è¿ç”±è‡ªå·±åˆ›é€ ï¼Œè¯·ç†æ€§çœ‹å¾…åˆ†æç»“æœã€‚
`;
```

## æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜ç­–ç•¥

```typescript
// lib/ai/cache.ts
import Redis from 'ioredis';

const redis = new Redis(process.env.REDIS_URL);

export async function getCachedInterpretation(
  key: string
): Promise<string | null> {
  const cached = await redis.get(`ai:${key}`);
  if (cached) {
    console.log('Cache hit');
    return cached;
  }
  return null;
}

export async function setCachedInterpretation(
  key: string,
  value: string,
  ttl = 3600
) {
  await redis.setex(`ai:${key}`, ttl, value);
}
```

### 2. æ‰¹é‡å¤„ç†

```typescript
// æ‰¹é‡ç”Ÿæˆè§£è¯»ï¼ˆèŠ‚çœ API è°ƒç”¨ï¼‰
export async function batchInterpretation(
  requests: InterpretationRequest[]
) {
  const prompts = requests.map(buildBaziPrompt);
  
  // å¹¶å‘è°ƒç”¨ï¼ˆé™åˆ¶å¹¶å‘æ•°ï¼‰
  const results = await pMap(
    prompts,
    async (prompt) => await generateInterpretation(prompt),
    { concurrency: 5 }
  );
  
  return results;
}
```

### 3. Token ä¼˜åŒ–

```typescript
// ä¼°ç®— token æ•°é‡
function estimateTokens(text: string): number {
  // ä¸­æ–‡ï¼š1 å­—ç¬¦ â‰ˆ 2 tokens
  // è‹±æ–‡ï¼š1 å•è¯ â‰ˆ 1.3 tokens
  const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
  const englishWords = (text.match(/[a-zA-Z]+/g) || []).length;
  
  return chineseChars * 2 + englishWords * 1.3;
}
```

## å¤šè¯­è¨€æ”¯æŒ

```typescript
// lib/ai/translation.ts
export async function translateInterpretation(
  text: string,
  targetLang: 'en' | 'zh'
) {
  const response = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: [
      {
        role: 'system',
        content: `Translate the following fortune-telling analysis to ${targetLang}. Keep the professional and empathetic tone.`
      },
      { role: 'user', content: text }
    ],
    temperature: 0.3, // ä½æ¸©åº¦ä¿è¯ç¿»è¯‘å‡†ç¡®æ€§
  });
  
  return response.choices[0].message.content;
}
```

## ç›‘æ§ä¸åˆ†æ

```typescript
// lib/ai/monitoring.ts
export function logAIMetrics(data: {
  model: string;
  tokens: number;
  latency: number;
  cost: number;
}) {
  // å‘é€åˆ° Application Insights
  appInsights.trackMetric({
    name: 'AI_Token_Usage',
    value: data.tokens,
  });
  
  appInsights.trackMetric({
    name: 'AI_Latency',
    value: data.latency,
  });
  
  // è®¡ç®—æˆæœ¬
  const costPerToken = 0.00003; // GPT-4 ä»·æ ¼
  const totalCost = data.tokens * costPerToken;
  
  console.log(`AI è°ƒç”¨: ${data.model}, è€—æ—¶ ${data.latency}ms, æˆæœ¬ $${totalCost.toFixed(4)}`);
}
```

## æˆæœ¬æ§åˆ¶

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | å¹³å‡æˆæœ¬/æ¬¡ |
|------|---------|---------|------------|
| GPT-4 Turbo | $0.01/1K | $0.03/1K | $0.08 |
| GPT-3.5 Turbo | $0.0005/1K | $0.0015/1K | $0.004 |

**ä¼˜åŒ–ç­–ç•¥ï¼š**
- æ™®é€šç”¨æˆ·ï¼šGPT-3.5 Turbo
- ä»˜è´¹ç”¨æˆ·ï¼šGPT-4 Turbo
- ç¼“å­˜çƒ­ç‚¹æ•°æ®ï¼ˆç›¸åŒå‘½ç›˜ï¼‰
- å‹ç¼© Promptï¼ˆå‡å°‘ tokenï¼‰

## ä¸‹ä¸€æ­¥

- [åç«¯æ¶æ„](/architecture/backend)
- [æ•°æ®åº“è®¾è®¡](/architecture/database)
- [OpenAI é›†æˆè¯¦è§£](/tech-stack/openai)

---

::: tip ğŸ’¡ æƒ³äº†è§£å®ç°ç»†èŠ‚ï¼Ÿ
æŸ¥çœ‹åšå®¢æ–‡ç«  [AI å åœæŠ€æœ¯å®ç°](/blog/ai-fortune-telling) äº†è§£æ›´å¤šã€‚
:::
